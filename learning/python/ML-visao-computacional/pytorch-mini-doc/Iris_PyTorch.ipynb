{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoFelixDeSousa/pytorch-mini-doc/blob/main/Iris_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6rPy33sZE9w"
      },
      "source": [
        "# Baixando o Dataset\n",
        "\n",
        "O código abaixo baixa o arquivo `Iris.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bgSGK47MVmj",
        "outputId": "075e850f-61f5-44d4-a4e6-006c4dc99ee2"
      },
      "source": [
        "!gdown --id '1d3NbjXro_BfnYpFm66ETBfe7ubAZPAoL'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d3NbjXro_BfnYpFm66ETBfe7ubAZPAoL\n",
            "To: /content/Iris.csv\n",
            "100% 5.11k/5.11k [00:00<00:00, 22.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm-9AefiZMJc"
      },
      "source": [
        "# Importação do PyTorch\n",
        "\n",
        "A seguir importamos a biblioteca PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTDh5qsMlrr"
      },
      "source": [
        "#Aqui importamos o módulo do PyTorch\n",
        "\n",
        "import torch\n",
        "\n",
        "# Em seguida ajustamos para suprimir a\n",
        "# notação científica na hora de imprimir\n",
        "# os tensores\n",
        "\n",
        "torch.set_printoptions(precision=2,sci_mode=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAJFUjETZdF0"
      },
      "source": [
        "# Leitura dos dados\n",
        "\n",
        "Nas linhas seguintes fazemos a leitura dos dados do arquivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3flfP46QMitf"
      },
      "source": [
        "# Abre o arquivo e faz uma leitura\n",
        "# das suas linhas\n",
        "\n",
        "f = open('Iris.csv', 'r')\n",
        "lines = f.readlines()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi-k1iZGMqVp"
      },
      "source": [
        "# 4 entradas\n",
        "X = torch.zeros(len(lines)-1,4)\n",
        "\n",
        "# 3 saídas desejadas (one-hot)\n",
        "Y = torch.zeros(len(lines)-1,3)\n",
        "\n",
        "# Teremos 3 categorias. O vetor abaixo lista as strings\n",
        "# que representam as categorias possíveis\n",
        "cats = ['Iris-setosa','Iris-versicolor','Iris-virginica']\n",
        "\n",
        "# Para cada linha do arquivo, exceto\n",
        "# a primeira linha que é o cabeçalho\n",
        "for i, line in enumerate(lines[1:]):\n",
        "\n",
        "  # Aqui decodificamos a linha para transformar\n",
        "  # de binário para caracteres ascii, e descartamos\n",
        "  # o último caractere que representa uma nova linha\n",
        "  s = line[:-1]\n",
        "\n",
        "  # Aqui separamos os dados por vírgulas,\n",
        "  # descartando o primeiro valor que é o id\n",
        "  # pois usaremos i do laço como id.\n",
        "  _,sl,sw,pl,pw,sp = s.split(',')\n",
        "\n",
        "  # Transformamos as strings que representam\n",
        "  # as dimensões de sépala e pétala para ponto\n",
        "  # flutuante.\n",
        "  sl = float(sl)\n",
        "  sw = float(sw)\n",
        "  pl = float(pl)\n",
        "  pw = float(pw)\n",
        "\n",
        "  # Aqui populamos as matrizes X e Y com os dados\n",
        "  # coletados.\n",
        "  X[i,:] = torch.tensor([sl,sw,pl,pw])\n",
        "  Y[i,:] = torch.tensor([1 if sp == cat else 0 for cat in cats])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht6wk1vFZnpR"
      },
      "source": [
        "# Embaralhamento e Separação de Dados de Validação\n",
        "\n",
        "A seguir embaralhamos os pares de entradas e respectivas saídas desejadas, separando uma parte das amostras para validação do resultado do treinamento da rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Wb7KcqMygj"
      },
      "source": [
        "import random\n",
        "\n",
        "# Aqui criamos uma lista de índices\n",
        "# embaralhados\n",
        "indexes = list(range(150))\n",
        "random.shuffle(indexes)\n",
        "\n",
        "# Essa variável T indica quantas amostras\n",
        "# serão usadas para treinamento. As demais\n",
        "# serão usadas para validação\n",
        "T = 140\n",
        "\n",
        "# Aqui preparamos as matrizes dos pares\n",
        "# de dados de treinamento e validação.\n",
        "Xt = torch.zeros(T,4)\n",
        "Yt = torch.zeros(T,3)\n",
        "Xv = torch.zeros(150-T,4)\n",
        "Yv = torch.zeros(150-T,3)\n",
        "\n",
        "# Aqui preenchemos as matrizes com os\n",
        "# respectivos valores\n",
        "for i in range(0,T):\n",
        "  Xt[i,:] = X[indexes[i],:]\n",
        "  Yt[i,:] = Y[indexes[i],:]\n",
        "for i in range(0,150-T):\n",
        "  Xv[i,:] = X[indexes[T+i],:]\n",
        "  Yv[i,:] = Y[indexes[T+i],:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BUIJdRqZzl6"
      },
      "source": [
        "# Módulos auxiliares\n",
        "\n",
        "Esses submódulos do PyTorch facilitam a construção de redes neurais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IxeNX_zM5cu"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkQg8B1Z7Rg"
      },
      "source": [
        "# Definição da Arquitetura\n",
        "\n",
        "No código a seguir criamos a rede neural como uma classe que deriva de `nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKjwEubHNLgb"
      },
      "source": [
        "# Essa é a classe da rede neural\n",
        "\n",
        "class Perceptron(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "    # Chamamos o construtor da classe\n",
        "    # mãe (nn.Module)\n",
        "\n",
        "    super(Perceptron, self).__init__()\n",
        "\n",
        "    # Criamos os objetos que implementam\n",
        "    # a parte referente à combinação linear\n",
        "    # (pesos sinapticos e biases)\n",
        "\n",
        "    self.c1 = nn.Linear(4, 8)\n",
        "    self.c2 = nn.Linear(8, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Aqui calculamos a parte\n",
        "    # linear da primeira\n",
        "    # camada\n",
        "\n",
        "    s1 = self.c1(x)\n",
        "\n",
        "    # Aplicamos a função de\n",
        "    # ativação sigmoide\n",
        "\n",
        "    z1 = torch.sigmoid(s1)\n",
        "\n",
        "    # E calculamos a parte\n",
        "    # linear da segunda e\n",
        "    # última camada.\n",
        "    s2 = self.c2(z1)\n",
        "\n",
        "    # Retornamos assim mesmo,\n",
        "    # sem ativação, já que a\n",
        "    # função softmax é implementada\n",
        "    # diretamente na hora de\n",
        "    # calcular o custo\n",
        "\n",
        "    return s2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs_L2lZgPFo9",
        "outputId": "2ea629af-311a-420b-c1cc-6188cbe4eea3"
      },
      "source": [
        "# Aqui instanciamos o objeto\n",
        "\n",
        "p = Perceptron()\n",
        "print(p)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron(\n",
            "  (c1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (c2): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnEOZd9pPXhv",
        "outputId": "f72e0701-d890-49e8-b377-ced1a9e2bd2c"
      },
      "source": [
        "# Esse método herdado da classe mãe\n",
        "# mostra todos os parâmetros, que\n",
        "# nesse caso são os pesos e biases\n",
        "# de todas as camadas.\n",
        "\n",
        "list(p.parameters())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.02,  0.11, -0.26, -0.33],\n",
              "         [-0.46, -0.03, -0.31, -0.04],\n",
              "         [-0.43, -0.25, -0.09,  0.23],\n",
              "         [ 0.38,  0.36,  0.03, -0.03],\n",
              "         [ 0.34, -0.43, -0.40,  0.44],\n",
              "         [-0.12, -0.03,  0.41, -0.02],\n",
              "         [-0.12, -0.19, -0.32,  0.46],\n",
              "         [ 0.37, -0.02, -0.25,  0.18]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.33, -0.10,  0.11, -0.07,  0.08,  0.45,  0.13, -0.30],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.14, -0.04,  0.04, -0.32, -0.06, -0.21,  0.21, -0.23],\n",
              "         [-0.03, -0.00, -0.26,  0.24,  0.27, -0.17,  0.28,  0.21],\n",
              "         [ 0.09, -0.33, -0.32, -0.31,  0.05,  0.15, -0.01, -0.28]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.27,  0.07, -0.28], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EErcOnN4blEy"
      },
      "source": [
        "# Função de Perda e Treinamento\n",
        "\n",
        "No código a seguir mostramos como pode ser aplicada uma função de perda e realizado o treinamento da rede neural."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5qRvua1PpGA",
        "outputId": "482795cc-4748-4032-aee4-42390a0be574"
      },
      "source": [
        "# Aqui criamos uma entrada arbitrária\n",
        "\n",
        "x = torch.tensor([[1.0,2.0,3.0,4.0]])\n",
        "\n",
        "# Calculamos a saída da rede neural\n",
        "# mesmo que ainda usando pesos e biases\n",
        "# aleatórios\n",
        "\n",
        "y = p(x)\n",
        "\n",
        "# E criamos uma saída desejada (arbitrária,\n",
        "# só para demonstração)\n",
        "y_hat = torch.tensor([[0.0, 1.0, 0.0]])\n",
        "\n",
        "# Essa linha de código cria o objeto\n",
        "# que implementa a função de perda do\n",
        "# tipo Entropia Cruzada\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# Aqui usamos o objeto criado para calcular\n",
        "# a função de perda aplicada à saída calculada\n",
        "# e saída desejada.\n",
        "\n",
        "e = loss(y, y_hat.argmax(dim=1))\n",
        "print(e)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.51, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAMU7f8rRQ84"
      },
      "source": [
        "# Esse erro acima pode ser propagado\n",
        "# para os parâmetros, calculando as\n",
        "# derivadas parciais do erro para\n",
        "# cada respectivo parâmetro (gradiente\n",
        "# do erro)\n",
        "\n",
        "# Aqui zeramos o gradiente (zeramos\n",
        "# as derivadas parciais do erro em\n",
        "# relação a cada um dos parâmetros\n",
        "# da rede neural)\n",
        "\n",
        "p.zero_grad()\n",
        "\n",
        "# Em seguida propagammos o gradiente\n",
        "# do erro de trás para frente, usando\n",
        "# a regra da cadeia (isso calcula as\n",
        "# derivadas parciais do erro para cada\n",
        "# um dos parâmetros da rede neural)\n",
        "\n",
        "e.backward()\n",
        "\n",
        "# No laço abaixo aplicamos uma pequena\n",
        "# correção de um passo de tamanho 0.1\n",
        "# no sentido contrário ao do gradiente\n",
        "# de cada parâmetro (descida do gradiente)\n",
        "\n",
        "for param in p.parameters():\n",
        "  param.data -= 0.1*param.grad"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE7WLQaWR0NL",
        "outputId": "0462bca5-69b0-4ee6-b1a6-77000ea4d4fe"
      },
      "source": [
        "# O código a seguir combina todas essas\n",
        "# etapas acima, fazendo efetivamente\n",
        "# o treinamento da rede neural para\n",
        "# todos os dados de treinamento que\n",
        "# já tínhamos separado inicialmente\n",
        "\n",
        "# Laço para 1001 épocas\n",
        "\n",
        "for i in range(1001):\n",
        "\n",
        "  # Para cada par de entrada\n",
        "  # e respectiva saída desejada\n",
        "  for x, y_hat in zip(Xt,Yt):\n",
        "\n",
        "    # Corrigimos o formato do\n",
        "    # par para que cada um seja\n",
        "    # um vetor linha (que é como\n",
        "    # o PyTorch espera)\n",
        "\n",
        "    x = x.view(1,4)\n",
        "    y_hat = y_hat.view(1,3)\n",
        "\n",
        "    # Zeramos os gradientes dos\n",
        "    # parâmetros para receberem\n",
        "    # os resultados novos\n",
        "    p.zero_grad()\n",
        "\n",
        "    # Computamos a saída calculada\n",
        "    # (caminho direto da rede neural)\n",
        "\n",
        "    y = p(x)\n",
        "\n",
        "    # Calculamos o erro entre a saída\n",
        "    # calculada e a desejada (lembrando\n",
        "    # que esse erro permite calcular\n",
        "    # o gradiente)\n",
        "    e = loss(y, y_hat.argmax(dim=1))\n",
        "\n",
        "    # Chamamos a função que computa\n",
        "    # o gradiente da função de erro\n",
        "    # para todos parâmetros da rede\n",
        "    # neural\n",
        "\n",
        "    e.backward()\n",
        "\n",
        "    # Aqui aplicamos uma correção dos\n",
        "    # parâmetros um passo de 0.1 na\n",
        "    # direção oposta ao gradiente do\n",
        "    # erro (subtraino 0.1 vezes a\n",
        "    # derivada parcial do erro em\n",
        "    # relação a cada respectivo\n",
        "    # parâmetro)\n",
        "\n",
        "    for param in p.parameters():\n",
        "      param.data -= 0.1*param.grad.data\n",
        "\n",
        "  # Imprimimos uma vez para\n",
        "  # cada 100 amostras\n",
        "  if not (i % 100):\n",
        "    print(float(e))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.506114661693573\n",
            "0.0038998278323560953\n",
            "0.0012056708801537752\n",
            "0.0010236029047518969\n",
            "0.000727627135347575\n",
            "0.0005902693956159055\n",
            "0.000619696278590709\n",
            "0.0003887851198669523\n",
            "0.00022706791060045362\n",
            "0.0003587556129787117\n",
            "0.0004804172203876078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn4te14CSRJb",
        "outputId": "1675413c-4490-45b6-9ce8-6bd223fd63e0"
      },
      "source": [
        "# O código dessa célula demonstra\n",
        "# como usar um otimizador, ao invés\n",
        "# de simplesmente subtrair passo vezes\n",
        "# gradiente.\n",
        "\n",
        "# Importamos o módulo que implementa\n",
        "# os otimizadores\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Escolhemos aqui o stochastic gradient descent\n",
        "# que é um dos otimizadores mais simples\n",
        "# que existem.\n",
        "\n",
        "optimizer = optim.SGD(p.parameters(), lr=0.1)\n",
        "\n",
        "# Esse laço aplica o otimizador acima\n",
        "# para todo dataset de treinamento,\n",
        "# repetindo o processo 10001 vezes.\n",
        "\n",
        "for i in range(10001):\n",
        "\n",
        "  # Zeramos os gradientes\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Calculamos as saídas da\n",
        "  # rede neural de uma vez,\n",
        "  # em lote, para todas entradas\n",
        "  # de treinamento.\n",
        "\n",
        "  Y = p(Xt)\n",
        "\n",
        "  # Calculamos o erro, em lote\n",
        "  e = loss(Y, Yt.argmax(dim=1))\n",
        "\n",
        "  # Fazemos a propagação reversa\n",
        "  # dos gradientes desse erro do\n",
        "  # lote\n",
        "\n",
        "  e.backward()\n",
        "\n",
        "  # Aplicamos um passo do otimizador\n",
        "  optimizer.step()\n",
        "\n",
        "  # Aqui imprimimos uma vez\n",
        "  # a cada mil épocas\n",
        "  if not (i % 1000):\n",
        "    print(float(e))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05577036365866661\n",
            "0.04364463686943054\n",
            "0.04306338354945183\n",
            "0.0427405871450901\n",
            "0.0424361452460289\n",
            "0.0421452634036541\n",
            "0.04186535254120827\n",
            "0.04159456118941307\n",
            "0.04133186861872673\n",
            "0.04107603803277016\n",
            "0.04082652926445007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTTbEwQ6fLlZ"
      },
      "source": [
        "# Rodando otimização na GPU\n",
        "\n",
        "Para rodar na GPU basta mover todos os dados para a GPU e rodar novamente a célula acima para que o treinamento aconteça dessa vez na GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqH3e3apS2NH"
      },
      "source": [
        "# Cria o objeto que representa\n",
        "# a GPU usando CUDA (NVidia)\n",
        "gpu = torch.device(\"cuda:0\")\n",
        "\n",
        "# Move rede neural e dados de\n",
        "# treinamento e validação, todos\n",
        "# para a GPU\n",
        "\n",
        "p.to(gpu)\n",
        "Xt = Xt.to(gpu)\n",
        "Yt = Yt.to(gpu)\n",
        "Xv = Xv.to(gpu)\n",
        "Yv = Yv.to(gpu)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYK6G808foFo"
      },
      "source": [
        "# Verificação dos Resultados\n",
        "\n",
        "Esse código abaixo mostra o resultado da rede neural aplicada aos dados de validação, comparando saída calculada e desejada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQsX54y3TQn1",
        "outputId": "4fe0a5b6-730c-4206-c053-c08ed0c6eaa8"
      },
      "source": [
        "Y = F.softmax(p(Xv), dim=1)\n",
        "for y, y_hat in zip(Y, Yv):\n",
        "  print(y.data, y_hat.data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0.00,     1.00,     0.00], device='cuda:0') tensor([0., 1., 0.], device='cuda:0')\n",
            "tensor([    0.00,     0.00,     1.00], device='cuda:0') tensor([0., 0., 1.], device='cuda:0')\n",
            "tensor([    0.00,     0.04,     0.96], device='cuda:0') tensor([0., 0., 1.], device='cuda:0')\n",
            "tensor([    1.00,     0.00,     0.00], device='cuda:0') tensor([1., 0., 0.], device='cuda:0')\n",
            "tensor([    1.00,     0.00,     0.00], device='cuda:0') tensor([1., 0., 0.], device='cuda:0')\n",
            "tensor([    0.00,     1.00,     0.00], device='cuda:0') tensor([0., 1., 0.], device='cuda:0')\n",
            "tensor([    1.00,     0.00,     0.00], device='cuda:0') tensor([1., 0., 0.], device='cuda:0')\n",
            "tensor([    1.00,     0.00,     0.00], device='cuda:0') tensor([1., 0., 0.], device='cuda:0')\n",
            "tensor([    1.00,     0.00,     0.00], device='cuda:0') tensor([1., 0., 0.], device='cuda:0')\n",
            "tensor([    0.00,     0.01,     0.99], device='cuda:0') tensor([0., 0., 1.], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}