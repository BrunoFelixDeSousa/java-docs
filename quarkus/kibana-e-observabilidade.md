# Kibana e Observabilidade - Guia Completo e DidÃ¡tico ğŸ”

## ğŸ“‘ Ãndice

1. [ğŸ¯ IntroduÃ§Ã£o ao Kibana](#-introduÃ§Ã£o-ao-kibana)
2. [ğŸ—ï¸ O Elastic Stack (ELK)](#ï¸-o-elastic-stack-elk)
3. [ğŸª Casos de Uso Principais](#-casos-de-uso-principais)
4. [ğŸ”„ Arquitetura de Observabilidade](#-arquitetura-de-observabilidade-com-quarkus--elk)
5. [ğŸ³ ConfiguraÃ§Ã£o de Ambiente com Docker](#-configuraÃ§Ã£o-de-ambiente)
6. [âš™ï¸ Configurando Logging no Quarkus](#ï¸-configurando-logging-no-quarkus)
7. [ğŸ“¤ Enviando Logs para o Elasticsearch](#-enviando-logs-para-o-elasticsearch)
8. [ğŸ“Š Usando Kibana](#-usando-kibana)
9. [ğŸ’» Exemplo PrÃ¡tico - E-commerce](#-exemplo-prÃ¡tico--quarkus--kibana)
10. [âœ… Boas PrÃ¡ticas](#-boas-prÃ¡ticas)
11. [ğŸ“ ExercÃ­cios PrÃ¡ticos](#-exercÃ­cios-prÃ¡ticos)
12. [ğŸš€ Recursos Extras e PrÃ³ximos Passos](#-recursos-extras-e-prÃ³ximos-passos)

---

## ğŸ¯ IntroduÃ§Ã£o ao Kibana

### O Que Ã‰ Kibana? - A Analogia do Painel de Controle ğŸ›ï¸

Imagine que vocÃª estÃ¡ pilotando um aviÃ£o:

| **Sem Kibana** âŒ | **Com Kibana** âœ… |
|-------------------|-------------------|
| Olhar pela janela e adivinhar a altitude | Painel com velocidade, altitude, combustÃ­vel |
| NÃ£o saber se hÃ¡ problemas no motor | Alertas automÃ¡ticos de anomalias |
| Depender de "sorte" para detectar falhas | VisÃ£o completa em tempo real |

**Kibana = Painel de Controle da Sua AplicaÃ§Ã£o**

### ğŸ’¡ O Que Kibana Faz?

âœ… **Visualiza dados** do Elasticsearch em dashboards interativos  
âœ… **Analisa logs** em tempo real com buscas poderosas  
âœ… **Cria alertas** automÃ¡ticos para problemas  
âœ… **Explora mÃ©tricas** de performance e comportamento  
âœ… **Detecta anomalias** usando Machine Learning  

**TL;DR:** Kibana transforma dados brutos em insights visuais acionÃ¡veis!

---

## ğŸ—ï¸ O Elastic Stack (ELK)

### Os 3 Pilares - Analogia da FÃ¡brica ğŸ­

```
ğŸ“¦ APLICAÃ‡ÃƒO QUARKUS
    â†“ Produz logs/mÃ©tricas (matÃ©ria-prima)
    
ğŸšš FILEBEAT/LOGSTASH
    â†“ Coleta e transporta dados
    
ğŸ­ ELASTICSEARCH
    â†“ Processa e armazena (fÃ¡brica)
    
ğŸ“Š KIBANA
    â†“ Apresenta produtos finais (showroom)
```

### Componentes Explicados

| Componente | FunÃ§Ã£o | Analogia |
|------------|--------|----------|
| **Elasticsearch** ğŸ” | Armazena e indexa dados | Biblioteca gigante com Ã­ndice perfeito |
| **Logstash/Filebeat** ğŸšš | Coleta e processa logs | CaminhÃ£o de entrega |
| **Kibana** ğŸ“Š | Interface de visualizaÃ§Ã£o | Dashboard do carro |

### Fluxo Completo

```mermaid
graph LR
    A[ğŸ¯ Quarkus App] -->|Logs JSON| B[ğŸ“ Arquivo]
    B -->|LÃª| C[ğŸšš Filebeat]
    C -->|Envia| D[ğŸ­ Elasticsearch]
    D -->|Consulta| E[ğŸ“Š Kibana]
    E -->|Visualiza| F[ğŸ‘¤ VocÃª]
```

---

## ğŸª Casos de Uso Principais

### 1ï¸âƒ£ AnÃ¡lise de Logs - Encontre Agulha no Palheiro

**Problema:** "Por que o pedido #12345 falhou Ã s 3h da manhÃ£?"

**Com Kibana:**
```kql
orderId: "12345" AND level: "ERROR" AND @timestamp: [2025-01-01T03:00 TO 2025-01-01T04:00]
```
ğŸ’¥ Encontra o erro em 2 segundos!

### 2ï¸âƒ£ Dashboards Operacionais - VisÃ£o em Tempo Real

**Antes:** "SerÃ¡ que a API estÃ¡ funcionando?"  
**Depois:** Dashboard mostrando:
- âœ… 99.9% uptime
- âš¡ 150ms tempo mÃ©dio de resposta
- ğŸ“ˆ 1.2K requests/minuto

### 3ï¸âƒ£ Alertas Proativos - Seja Avisado Antes do Desastre

```
ğŸš¨ ALERTA: Taxa de erro subiu para 15% nos Ãºltimos 5 minutos!
ğŸ“§ Email enviado para: ops@empresa.com
ğŸ“± Slack notificado: #alerts-prod
```

### 4ï¸âƒ£ Monitoramento em Tempo Real

```
AGORA (12:34:56)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Requests/s:    245 â¬†ï¸
Erros:         2   âœ…
Response Time: 89ms âš¡
CPU:          45%  âœ…
```

### 5ï¸âƒ£ AnÃ¡lise de SeguranÃ§a

```
ğŸ”’ ANOMALIA DETECTADA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- 1000 tentativas de login do IP 192.168.1.100
- PossÃ­vel ataque de forÃ§a bruta
- AÃ§Ã£o: Bloquear IP automaticamente
```

---

## ğŸ”„ Arquitetura de Observabilidade com Quarkus + ELK

### Fluxo Completo de Dados - Passo a Passo

```mermaid
sequenceDiagram
    participant Q as ğŸ¯ Quarkus App
    participant F as ğŸšš Filebeat
    participant E as ğŸ­ Elasticsearch
    participant K as ğŸ“Š Kibana
    participant U as ğŸ‘¤ VocÃª

    Q->>Q: 1. Gera logs JSON estruturados
    Q->>F: 2. Escreve em /logs/app.log
    F->>F: 3. LÃª e processa logs
    F->>E: 4. Envia via HTTP
    E->>E: 5. Indexa e armazena
    U->>K: 6. Acessa dashboard
    K->>E: 7. Consulta dados
    E->>K: 8. Retorna resultados
    K->>U: 9. Mostra visualizaÃ§Ãµes
```

### ğŸ¯ BenefÃ­cios da IntegraÃ§Ã£o

| **Recurso** | **BenefÃ­cio** | **Impacto** |
|-------------|---------------|-------------|
| **Logs JSON** | Estruturados e fÃ¡ceis de consultar | âš¡ Buscas 10x mais rÃ¡pidas |
| **Tempo Real** | Dados em Kibana em segundos | ğŸš€ Debugging instantÃ¢neo |
| **Escalabilidade** | Elasticsearch distribui dados | ğŸ“ˆ Suporta bilhÃµes de logs |
| **Flexibilidade** | VisualizaÃ§Ãµes customizadas | ğŸ¨ Dashboards sob medida |
| **CorrelaÃ§Ã£o** | Une logs, mÃ©tricas e traces | ğŸ”— VisÃ£o 360Â° da aplicaÃ§Ã£o |

### ğŸ’» Exemplo Real - O Que Acontece?

**VocÃª faz uma requisiÃ§Ã£o:**
```bash
curl -X POST http://localhost:8080/api/pedidos \
  -H "Content-Type: application/json" \
  -d '{"produtoId": 123, "quantidade": 2}'
```

**Quarkus gera log:**
```json
{
  "timestamp": "2025-09-30T14:30:15.123Z",
  "level": "INFO",
  "message": "Pedido criado com sucesso",
  "orderId": "abc-123",
  "userId": "user-42",
  "duration": "45ms"
}
```

**Filebeat captura â†’ Elasticsearch armazena â†’ Kibana mostra:**
```
âœ… Pedido abc-123 criado
â±ï¸ Tempo: 45ms
ğŸ‘¤ UsuÃ¡rio: user-42
ğŸ“… 2025-09-30 14:30:15
```

**VocÃª vÃª tudo em 1-2 segundos! ğŸš€**

---

## ğŸ³ ConfiguraÃ§Ã£o de Ambiente

### Docker Compose para ELK Stack Completo

**TL;DR:** Um comando para subir tudo: Elasticsearch + Kibana + Filebeat

**Crie `docker-compose.yml`:**

```yaml
version: '3.8'

services:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ­ ELASTICSEARCH - Armazena os dados
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.1.2
    container_name: elasticsearch
    environment:
      # Modo single-node (desenvolvimento)
      - discovery.type=single-node
      # Desabilitar seguranÃ§a (sÃ³ para DEV!)
      - xpack.security.enabled=false
      # MemÃ³ria JVM (ajuste conforme necessÃ¡rio)
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    ports:
      - "9200:9200"  # API REST
      - "9300:9300"  # ComunicaÃ§Ã£o entre nÃ³s
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸ“Š KIBANA - Interface de visualizaÃ§Ã£o
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  kibana:
    image: docker.elastic.co/kibana/kibana:9.1.2
    container_name: kibana
    ports:
      - "5601:5601"  # Interface web
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - xpack.security.enabled=false
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - elk-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # ğŸšš FILEBEAT - Coleta logs
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  filebeat:
    image: docker.elastic.co/beats/filebeat:9.1.2
    container_name: filebeat
    user: root  # NecessÃ¡rio para ler logs Docker
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./logs:/logs:ro  # Seus logs da aplicaÃ§Ã£o
    networks:
      - elk-network
    depends_on:
      elasticsearch:
        condition: service_healthy

volumes:
  elasticsearch-data:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### ğŸš€ Inicializando o Ambiente

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1ï¸âƒ£ PREPARAR ESTRUTURA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
mkdir -p logs

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2ï¸âƒ£ SUBIR OS SERVIÃ‡OS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
docker-compose up -d

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3ï¸âƒ£ VERIFICAR STATUS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
docker-compose ps

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4ï¸âƒ£ TESTAR ELASTICSEARCH
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
curl http://localhost:9200
# Resposta esperada: {"name":"...", "cluster_name":"...", "version":{...}}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5ï¸âƒ£ ACESSAR KIBANA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Browser: http://localhost:5601
```

**â±ï¸ Tempo de inicializaÃ§Ã£o:** ~2-3 minutos para tudo estar pronto!

---

## 4. Configurando Logging no Quarkus

### DependÃªncias Maven

Adicione as dependÃªncias necessÃ¡rias no `pom.xml`:

```xml
<dependencies>
    <!-- Quarkus Logging JSON -->
    <dependency>
        <groupId>io.quarkus</groupId>
        <artifactId>quarkus-logging-json</artifactId>
    </dependency>

    <!-- Para mÃ©tricas (opcional) -->
    <dependency>
        <groupId>io.quarkus</groupId>
        <artifactId>quarkus-micrometer-registry-prometheus</artifactId>
    </dependency>

    <!-- Para health checks -->
    <dependency>
        <groupId>io.quarkus</groupId>
        <artifactId>quarkus-smallrye-health</artifactId>
    </dependency>
</dependencies>

```

### ConfiguraÃ§Ã£o de Logging

Configure o `application.properties`:

```bash
# Logging bÃ¡sico
quarkus.log.level=INFO
quarkus.log.console.json=true
quarkus.log.console.json.pretty-print=false

# ConfiguraÃ§Ãµes especÃ­ficas para diferentes pacotes
quarkus.log.category."com.example.service".level=DEBUG
quarkus.log.category."org.hibernate".level=WARN

# Logging para arquivo (para coleta via Filebeat)
quarkus.log.file.enable=true
quarkus.log.file.path=logs/application.log
quarkus.log.file.format=%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n
quarkus.log.file.json=true

# ConfiguraÃ§Ãµes de performance
quarkus.log.console.async=true
quarkus.log.file.async=true

```

### Exemplo de Estrutura de Log

Com a configuraÃ§Ã£o acima, seus logs ficarÃ£o assim:

```json
{
  "timestamp": "2025-08-22T10:15:30.123Z",
  "sequence": 1234,
  "loggerClassName": "org.jboss.logging.Logger",
  "loggerName": "com.example.service.OrderService",
  "level": "INFO",
  "message": "Pedido processado com sucesso",
  "threadName": "executor-thread-1",
  "threadId": 23,
  "mdc": {
    "orderId": "12345",
    "userId": "user123",
    "correlationId": "abc-def-ghi"
  },
  "ndc": "",
  "hostName": "quarkus-app-01",
  "processId": 1
}

```

## 5. Enviando Logs para o Elasticsearch

### ConfiguraÃ§Ã£o do Filebeat

Crie o arquivo `filebeat.yml`:

```yaml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /logs/application.log
  json.keys_under_root: true
  json.add_error_key: true
  json.message_key: message
  fields:
    service: quarkus-app
    environment: development
  fields_under_root: true

# Processamento adicional
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - decode_json_fields:
      fields: ["message"]
      target: ""
      overwrite_keys: true

# Output para Elasticsearch
output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "quarkus-logs-%{+yyyy.MM.dd}"
  template.enabled: true
  template.pattern: "quarkus-logs-*"
  template.settings:
    index.number_of_shards: 1
    index.number_of_replicas: 0

# Logging do Filebeat
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

```

### Alternativa: Logstash

Para casos mais complexos, use Logstash com este pipeline:

```ruby
# pipeline/quarkus-logs.conf
input {
  file {
    path => "/logs/application.log"
    start_position => "beginning"
    codec => json
    tags => ["quarkus", "application"]
  }
}

filter {
  if [level] == "ERROR" {
    mutate {
      add_tag => ["error"]
    }
  }

  if [loggerName] =~ /Controller/ {
    mutate {
      add_tag => ["controller"]
    }
  }

  # Parse de mÃ©tricas customizadas
  if [message] =~ /duration=(\d+)ms/ {
    grok {
      match => { "message" => "duration=(?<request_duration>\d+)ms" }
    }
    mutate {
      convert => { "request_duration" => "integer" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "quarkus-logs-%{+YYYY.MM.dd}"
  }

  # Debug output
  stdout { codec => rubydebug }
}

```

## 6. Usando Kibana

### ConfiguraÃ§Ã£o Inicial

1. **Acesse o Kibana**: `http://localhost:5601`
2. **Configure Index Patterns**:
    - VÃ¡ para **Stack Management > Index Patterns**
    - Clique em **Create Index Pattern**
    - Digite `quarkus-logs-*`
    - Escolha `@timestamp` como time field

### Descoberta de Dados

Na aba **Discover**, vocÃª pode:

- Explorar logs em tempo real
- Aplicar filtros por nÃ­vel de log, serviÃ§o, etc.
- Buscar por texto especÃ­fico
- Analisar campos estruturados

```
# Exemplos de consultas KQL (Kibana Query Language)
level: "ERROR"
loggerName: "com.example.service.OrderService"
mdc.orderId: "12345"
message: "timeout" AND level: "WARN"

```

### Criando VisualizaÃ§Ãµes

### 1. GrÃ¡fico de Barras - Logs por NÃ­vel

```yaml
VisualizaÃ§Ã£o: Vertical Bar Chart
X-Axis:
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Auto
Y-Axis:
  - Aggregation: Count
Split Series:
  - Aggregation: Terms
  - Field: level.keyword
  - Size: 10

```

### 2. Tabela de Top Erros

```yaml
VisualizaÃ§Ã£o: Data Table
Metrics:
  - Aggregation: Count
Buckets:
  - Aggregation: Terms
  - Field: message.keyword
  - Size: 20
  - Order: Metric Count (Descending)
Filters: level: "ERROR"

```

### 3. Mapa de Calor - Atividade por Hora

```yaml
VisualizaÃ§Ã£o: Heat Map
Y-Axis:
  - Aggregation: Terms
  - Field: loggerName.keyword
X-Axis:
  - Aggregation: Date Histogram
  - Field: @timestamp
  - Interval: Hourly

```

### Dashboard Completo

Crie um dashboard combinando as visualizaÃ§Ãµes:

```mermaid
graph TB
    A[Dashboard: Quarkus Observability] --> B[Total Requests/min]
    A --> C[Error Rate %]
    A --> D[Response Time P95]
    A --> E[Top Errors Table]
    A --> F[Log Levels Over Time]
    A --> G[Services Activity Heatmap]

```

## 7. Exemplo PrÃ¡tico â€” Quarkus + Kibana

### AplicaÃ§Ã£o de Exemplo

Vamos criar uma aplicaÃ§Ã£o de e-commerce simples:

```java
@RestController
@RequestMapping("/api/orders")
@Slf4j
public class OrderController {

    @Autowired
    private OrderService orderService;

    @PostMapping
    public ResponseEntity<Order> createOrder(@RequestBody CreateOrderRequest request) {
        String correlationId = UUID.randomUUID().toString();
        MDC.put("correlationId", correlationId);
        MDC.put("operation", "create_order");
        MDC.put("userId", request.getUserId());

        try {
            log.info("Iniciando criaÃ§Ã£o de pedido para usuÃ¡rio: {}", request.getUserId());

            Order order = orderService.createOrder(request);

            log.info("Pedido criado com sucesso: orderId={}, total={}",
                    order.getId(), order.getTotal());

            return ResponseEntity.ok(order);
        } catch (InsufficientStockException e) {
            log.warn("Estoque insuficiente para o pedido: productId={}, requested={}, available={}",
                    e.getProductId(), e.getRequestedQuantity(), e.getAvailableQuantity());
            throw e;
        } catch (Exception e) {
            log.error("Erro inesperado ao criar pedido", e);
            throw e;
        } finally {
            MDC.clear();
        }
    }

    @GetMapping("/{orderId}")
    public ResponseEntity<Order> getOrder(@PathVariable String orderId) {
        MDC.put("orderId", orderId);

        try {
            long startTime = System.currentTimeMillis();
            Order order = orderService.findById(orderId);
            long duration = System.currentTimeMillis() - startTime;

            log.info("Pedido recuperado com sucesso: duration={}ms", duration);
            return ResponseEntity.ok(order);
        } catch (OrderNotFoundException e) {
            log.warn("Pedido nÃ£o encontrado: orderId={}", orderId);
            throw e;
        } finally {
            MDC.clear();
        }
    }
}

```

```java
@Service
@Slf4j
public class OrderService {

    @Autowired
    private ProductService productService;

    @Autowired
    private PaymentService paymentService;

    @Timed(name = "order_creation_time", description = "Time taken to create an order")
    public Order createOrder(CreateOrderRequest request) {
        MDC.put("method", "createOrder");

        log.debug("Validando itens do pedido: itemCount={}", request.getItems().size());

        // Simular algum processamento
        List<OrderItem> items = validateAndProcessItems(request.getItems());

        BigDecimal total = items.stream()
                .map(OrderItem::getSubtotal)
                .reduce(BigDecimal.ZERO, BigDecimal::add);

        log.debug("Total calculado: {}", total);

        // Processar pagamento
        boolean paymentSuccess = paymentService.processPayment(request.getPaymentInfo(), total);

        if (!paymentSuccess) {
            log.error("Falha no processamento do pagamento: amount={}", total);
            throw new PaymentProcessingException("Falha no pagamento");
        }

        Order order = Order.builder()
                .id(UUID.randomUUID().toString())
                .userId(request.getUserId())
                .items(items)
                .total(total)
                .status(OrderStatus.CONFIRMED)
                .createdAt(Instant.now())
                .build();

        log.info("Pedido processado: orderId={}, itemCount={}, total={}",
                order.getId(), items.size(), total);

        return order;
    }

    private List<OrderItem> validateAndProcessItems(List<CreateOrderItemRequest> items) {
        return items.stream().map(item -> {
            log.debug("Validando item: productId={}, quantity={}",
                    item.getProductId(), item.getQuantity());

            Product product = productService.findById(item.getProductId());

            if (product.getStock() < item.getQuantity()) {
                throw new InsufficientStockException(
                    item.getProductId(),
                    item.getQuantity(),
                    product.getStock()
                );
            }

            return OrderItem.builder()
                    .productId(item.getProductId())
                    .productName(product.getName())
                    .quantity(item.getQuantity())
                    .unitPrice(product.getPrice())
                    .subtotal(product.getPrice().multiply(new BigDecimal(item.getQuantity())))
                    .build();
        }).collect(Collectors.toList());
    }
}

```

### Gerando Dados de Teste

Script para gerar dados de teste:

```java
@Component
@Profile("dev")
public class DataGenerator {

    @Autowired
    private OrderController orderController;

    @Scheduled(fixedDelay = 5000) // A cada 5 segundos
    public void generateRandomOrders() {
        try {
            CreateOrderRequest request = generateRandomRequest();
            orderController.createOrder(request);
        } catch (Exception e) {
            // Erros intencionais para gerar logs interessantes
            log.error("Erro simulado na geraÃ§Ã£o de dados", e);
        }
    }

    private CreateOrderRequest generateRandomRequest() {
        Random random = new Random();

        // Simular falhas ocasionais
        if (random.nextDouble() < 0.1) { // 10% de chance de erro
            throw new RuntimeException("Erro simulado de rede");
        }

        return CreateOrderRequest.builder()
                .userId("user" + random.nextInt(100))
                .items(generateRandomItems())
                .paymentInfo(generatePaymentInfo())
                .build();
    }
}

```

### Logs Resultantes

Com a aplicaÃ§Ã£o rodando, vocÃª verÃ¡ logs como:

```json
{
  "timestamp": "2025-08-22T14:30:15.123Z",
  "level": "INFO",
  "loggerName": "com.example.controller.OrderController",
  "message": "Iniciando criaÃ§Ã£o de pedido para usuÃ¡rio: user42",
  "mdc": {
    "correlationId": "550e8400-e29b-41d4-a716-446655440000",
    "operation": "create_order",
    "userId": "user42"
  }
}

{
  "timestamp": "2025-08-22T14:30:15.456Z",
  "level": "INFO",
  "loggerName": "com.example.service.OrderService",
  "message": "Pedido processado: orderId=abc-123, itemCount=3, total=299.97",
  "mdc": {
    "correlationId": "550e8400-e29b-41d4-a716-446655440000",
    "method": "createOrder",
    "userId": "user42"
  }
}

{
  "timestamp": "2025-08-22T14:30:16.789Z",
  "level": "ERROR",
  "loggerName": "com.example.service.OrderService",
  "message": "Falha no processamento do pagamento: amount=599.99",
  "mdc": {
    "correlationId": "550e8400-e29b-41d4-a716-446655440001",
    "operation": "create_order",
    "userId": "user15"
  },
  "stackTrace": "com.example.exception.PaymentProcessingException: Falha no pagamento\n\tat com.example.service.OrderService.createOrder(OrderService.java:45)"
}

```

## 8. Boas PrÃ¡ticas

### EstruturaÃ§Ã£o de Logs com MDC

Use o **Mapped Diagnostic Context** para enriquecer logs:

```java
@Component
public class LoggingInterceptor implements HandlerInterceptor {

    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) {
        String correlationId = request.getHeader("X-Correlation-ID");
        if (correlationId == null) {
            correlationId = UUID.randomUUID().toString();
        }

        MDC.put("correlationId", correlationId);
        MDC.put("requestUri", request.getRequestURI());
        MDC.put("httpMethod", request.getMethod());
        MDC.put("userAgent", request.getHeader("User-Agent"));
        MDC.put("remoteAddr", request.getRemoteAddr());

        return true;
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) {
        MDC.clear(); // Importante para evitar memory leaks
    }
}

```

### ConfiguraÃ§Ã£o por Ambiente

```yaml
# application-dev.yml
quarkus:
  log:
    level: DEBUG
    console:
      json: true
    file:
      enable: true
      level: DEBUG

# application-prod.yml
quarkus:
  log:
    level: INFO
    console:
      json: true
    file:
      enable: true
      level: WARN
    category:
      "com.example":
        level: INFO
      "root":
        level: WARN

```

### SeguranÃ§a nos Logs

```java
@Component
public class SecuritySanitizer {

    private static final Set<String> SENSITIVE_FIELDS = Set.of(
        "password", "token", "authorization", "credit_card", "ssn"
    );

    public String sanitizeMessage(String message) {
        return SENSITIVE_FIELDS.stream()
                .reduce(message, (msg, field) ->
                    msg.replaceAll("(?i)" + field + "=[^\\s,}]+", field + "=***"));
    }
}

// Uso em logs
log.info("User login attempt: {}", sanitizer.sanitizeMessage(loginData.toString()));

```

### Ãndices por Ambiente

Configure Ã­ndices separados para cada ambiente:

```yaml
# filebeat-prod.yml
output.elasticsearch:
  hosts: ["elasticsearch-prod:9200"]
  index: "prod-quarkus-logs-%{+yyyy.MM.dd}"

# filebeat-staging.yml
output.elasticsearch:
  hosts: ["elasticsearch-staging:9200"]
  index: "staging-quarkus-logs-%{+yyyy.MM.dd}"

```

### RetenÃ§Ã£o de Dados

Configure polÃ­ticas de retenÃ§Ã£o no Elasticsearch:

```json
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50gb",
            "max_age": "30d"
          }
        }
      },
      "warm": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "cold": {
        "min_age": "90d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "365d"
      }
    }
  }
}

```

## 9. ExercÃ­cios PrÃ¡ticos

### ExercÃ­cio 1: Dashboard de Performance

**Objetivo**: Criar um dashboard mostrando mÃ©tricas de performance da aplicaÃ§Ã£o.

**Passos**:

1. Modifique os logs para incluir tempo de resposta:

```java
@Around("@annotation(org.springframework.web.bind.annotation.GetMapping)")
public Object logExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable {
    long start = System.currentTimeMillis();
    Object result = joinPoint.proceed();
    long duration = System.currentTimeMillis() - start;

    log.info("Request completed: endpoint={}, duration={}ms",
            joinPoint.getSignature().getName(), duration);
    return result;
}

```

1. Configure Logstash para extrair mÃ©tricas:

```ruby
filter {
  grok {
    match => { "message" => "Request completed: endpoint=%{WORD:endpoint}, duration=%{NUMBER:response_time:int}ms" }
  }
}

```

1. No Kibana, crie visualizaÃ§Ãµes para:
    - **Line Chart**: Tempo mÃ©dio de resposta por endpoint ao longo do tempo
    - **Metric**: P95 de tempo de resposta
    - **Data Table**: Top endpoints mais lentos

### ExercÃ­cio 2: Alertas de Erro

**Objetivo**: Configurar alertas para detectar picos de erro.

**ConfiguraÃ§Ã£o no Kibana**:

```json
{
  "trigger": {
    "schedule": {
      "interval": "1m"
    }
  },
  "input": {
    "search": {
      "request": {
        "search_type": "query_then_fetch",
        "indices": ["quarkus-logs-*"],
        "body": {
          "query": {
            "bool": {
              "filter": [
                {
                  "term": {
                    "level.keyword": "ERROR"
                  }
                },
                {
                  "range": {
                    "@timestamp": {
                      "gte": "now-5m"
                    }
                  }
                }
              ]
            }
          }
        }
      }
    }
  },
  "condition": {
    "compare": {
      "ctx.payload.hits.total": {
        "gt": 10
      }
    }
  },
  "actions": {
    "send_email": {
      "email": {
        "to": ["admin@company.com"],
        "subject": "High Error Rate Detected",
        "body": "More than 10 errors in the last 5 minutes"
      }
    }
  }
}

```

### ExercÃ­cio 3: IntegraÃ§Ã£o com Micrometer

**Objetivo**: Combinar logs com mÃ©tricas do Micrometer.

1. Adicione mÃ©tricas customizadas:

```java
@Component
public class MetricsService {

    private final Counter orderCounter;
    private final Timer orderProcessingTimer;

    public MetricsService(MeterRegistry meterRegistry) {
        this.orderCounter = Counter.builder("orders.created.total")
                .description("Total orders created")
                .register(meterRegistry);

        this.orderProcessingTimer = Timer.builder("orders.processing.duration")
                .description("Order processing time")
                .register(meterRegistry);
    }

    public void recordOrderCreated(String userId, BigDecimal amount) {
        orderCounter.increment(
            Tags.of(
                "user_type", determineUserType(userId),
                "amount_range", determineAmountRange(amount)
            )
        );
    }
}

```

1. Envie mÃ©tricas para Elasticsearch via Metricbeat:

```yaml
metricbeat.modules:
- module: prometheus
  period: 10s
  hosts: ["localhost:8080"]
  metrics_path: /q/metrics
  namespace: "quarkus"

```

1. Correlacione logs e mÃ©tricas no Kibana usando correlation IDs.

## 10. Recursos Extras e PrÃ³ximos Passos

### DocumentaÃ§Ã£o Oficial

- [Quarkus Logging Guide](https://quarkus.io/guides/logging)
- [Elastic Stack Documentation](https://www.elastic.co/guide/index.html)
- [Kibana User Guide](https://www.elastic.co/guide/en/kibana/current/index.html)

### Ferramentas Complementares

**APM (Application Performance Monitoring)**:

```yaml
# Elastic APM para Quarkus
quarkus.elastic-apm.service-name=quarkus-order-service
quarkus.elastic-apm.server-url=http://apm-server:8200
quarkus.elastic-apm.environment=production

```

**Machine Learning no Elastic**:

- DetecÃ§Ã£o automÃ¡tica de anomalias
- PrevisÃ£o de tendÃªncias
- Clustering de logs similares

### Exemplo Completo no GitHub

```bash
git clone https://github.com/elastic/examples
cd examples/quarkus-observability
docker-compose up -d

```

### PrÃ³ximos Passos

1. **Distributed Tracing**: Integre com Jaeger ou Zipkin
2. **CorrelaÃ§Ã£o Cross-Service**: Use correlation IDs entre microserviÃ§os
3. **Synthetic Monitoring**: Configure testes automÃ¡ticos de endpoints
4. **Cost Optimization**: Implemente hot/warm/cold storage tiers
5. **Security**: Configure autenticaÃ§Ã£o e autorizaÃ§Ã£o no Elastic Stack

### Template de Projeto

Use este template para iniciar rapidamente:

```bash
# Estrutura de projeto recomendada
quarkus-observability-project/
â”œâ”€â”€ src/main/java/
â”‚   â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ exception/
â”‚   â””â”€â”€ config/
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ filebeat.yml
â”œâ”€â”€ kibana/
â”‚   â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ index-patterns/
â”‚   â””â”€â”€ visualizations/
â””â”€â”€ scripts/
    â”œâ”€â”€ setup-elasticsearch.sh
    â””â”€â”€ import-kibana-objects.sh

```

Com este guia completo, vocÃª tem todas as ferramentas necessÃ¡rias para implementar observabilidade robusta em suas aplicaÃ§Ãµes Quarkus usando o Elastic Stack. A combinaÃ§Ã£o de logs estruturados, visualizaÃ§Ãµes interativas e alertas proativos fornece visibilidade completa sobre o comportamento e a performance das suas aplicaÃ§Ãµes em produÃ§Ã£o.